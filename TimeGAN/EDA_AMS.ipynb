{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration\n"
      ],
      "metadata": {
        "id": "ket9lCA5bzHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbiI8ZirRPeH",
        "outputId": "0f734881-27d7-49c4-e461-1815e60be9bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TimeGAN'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 77 (delta 29), reused 25 (delta 25), pack-reused 37\u001b[K\n",
            "Receiving objects: 100% (77/77), 1.29 MiB | 3.21 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jsyoon0823/TimeGAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the actual file name\n",
        "file_path = '/content/TimeGAN/data/stock_data.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "stock = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(stock.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlwVVmQSRdti",
        "outputId": "f1cc481b-3caf-49be-d103-703e8387a242"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Open       High        Low      Close  Adj_Close    Volume\n",
            "0  49.676899  51.693783  47.669952  49.845802  49.845802  44994500\n",
            "1  50.178635  54.187561  49.925285  53.805050  53.805050  23005800\n",
            "2  55.017166  56.373344  54.172661  54.346527  54.346527  18393200\n",
            "3  55.260582  55.439419  51.450363  52.096165  52.096165  15361800\n",
            "4  52.140873  53.651051  51.604362  52.657513  52.657513   9257400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The number of rows and columns in the data are:\", stock.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xti-J7swS1Fr",
        "outputId": "1109933c-de51-4ede-f773-bb5267a3defd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of rows and columns in the data are: (3685, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = stock.isnull()\n",
        "\n",
        "# Summarize null values in each column\n",
        "null_count = stock.isnull().sum()\n",
        "\n",
        "# Display the count of null values in each column\n",
        "print(\"\\nCount of null values in each column:\")\n",
        "print(null_count)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-_mNtEPS8RK",
        "outputId": "977e81fb-78ed-493d-bcbd-d6ff657a0177"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Count of null values in each column:\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj_Close    0\n",
            "Volume       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess: Dataloading.py"
      ],
      "metadata": {
        "id": "RGrt8et97VUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "3LqXkq8p4P8d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalisaion of data"
      ],
      "metadata": {
        "id": "trFx-nstQEmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MinMaxScaler(data):  # used to normalise the data\n",
        "  \"\"\"Min Max normalizer.\n",
        "\n",
        "  Args:\n",
        "    - data: original data\n",
        "\n",
        "  Returns:\n",
        "    - norm_data: normalized data\n",
        "  \"\"\"\n",
        "  numerator = data - np.min(data, 0)\n",
        "  denominator = np.max(data, 0) - np.min(data, 0)\n",
        "  norm_data = numerator / (denominator + 1e-7)\n",
        "  return norm_data\n",
        "\n"
      ],
      "metadata": {
        "id": "rQ1UIbK-4Z9R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalised_stock= MinMaxScaler(stock)\n",
        "print(normalised_stock.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31oFWw9u78fz",
        "outputId": "b37f1297-f854-41c4-ea9b-9f232daa6dac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Open      High       Low     Close  Adj_Close    Volume\n",
            "0  0.000329  0.000942  0.000000  0.000135   0.000135  0.543578\n",
            "1  0.000740  0.002981  0.001877  0.003383   0.003383  0.277886\n",
            "2  0.004700  0.004767  0.005413  0.003828   0.003828  0.222151\n",
            "3  0.004900  0.004004  0.003147  0.001981   0.001981  0.185523\n",
            "4  0.002346  0.002542  0.003275  0.002442   0.002442  0.111763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slice and shuffle data before loading\n",
        "**Independent and Identically Distributed** (i.i.d.) Assumption: Many machine learning models assume that the training data is i.i.d. Shuffling the data helps to approximate this condition.\n",
        "\n",
        "**Prevent Overfitting:** Shuffling ensures that the model sees a diverse set of patterns in each batch, which helps in preventing overfitting to specific sequences.\n",
        "\n",
        "**Better Generalization:** By mixing the sequences, the model is less likely to memorize the order of the data and more likely to learn generalizable patterns."
      ],
      "metadata": {
        "id": "10XVp14EISUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def real_data_loading (data_name, seq_len): # to shuffle the dataset\n",
        "  \"\"\"Load and preprocess real-world datasets.\n",
        "\n",
        "  Args:\n",
        "    - data_name: stock or energy\n",
        "    - seq_len: sequence length\n",
        "\n",
        "  Returns:\n",
        "    - data: preprocessed data.\n",
        "  \"\"\"\n",
        "  assert data_name in ['stock','energy']\n",
        "\n",
        "  if data_name == 'stock':\n",
        "    ori_data = np.loadtxt('/content/TimeGAN/data/stock_data.csv', delimiter = \",\",skiprows = 1)\n",
        "  elif data_name == 'energy':\n",
        "    ori_data = np.loadtxt('data/energy_data.csv', delimiter = \",\",skiprows = 1)\n",
        "\n",
        "  # Flip the data to make chronological data\n",
        "  ori_data = ori_data[::-1]\n",
        "  # Normalize the data\n",
        "  ori_data = MinMaxScaler(ori_data)\n",
        "\n",
        "  # Preprocess the dataset\n",
        "  temp_data = []    #\n",
        "  # Cut data by sequence length\n",
        "  for i in range(0, len(ori_data) - seq_len):\n",
        "    _x = ori_data[i:i + seq_len]              #slicing of data as lists of seqence length\n",
        "    temp_data.append(_x)\n",
        "\n",
        "  # Mix the datasets (to make it similar to i.i.d)\n",
        "  idx = np.random.permutation(len(temp_data))    #shuffling of the lists in temp data\n",
        "  data = []\n",
        "  for i in range(len(temp_data)):\n",
        "    data.append(temp_data[idx[i]])              #shuffled lists of lists as final data\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "tS7cr0e77iHj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "original_data = real_data_loading(\"stock\", 24)\n",
        "\n"
      ],
      "metadata": {
        "id": "M7HItO2KKCqX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data[0][:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJXAHGfWOVpf",
        "outputId": "5798cba9-806d-42cb-db3c-962972d0aae8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47147531, 0.47279136, 0.47166331, 0.47897112, 0.4818403 ,\n",
              "       0.49075029, 0.48016458, 0.48077765, 0.47028185, 0.47021649,\n",
              "       0.46889221, 0.47082138, 0.46247542, 0.45197962, 0.46525469,\n",
              "       0.46086511, 0.45965528, 0.47840709, 0.47928993, 0.48477489,\n",
              "       0.47506384, 0.4634073 , 0.4485955 , 0.48188116])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [0.19997616, 0.20317213, 0.20302168, 0.19481623, 0.18826976,\n",
        "       0.18364251, 0.1816298 , 0.18290655, 0.18382956, 0.18653354,\n",
        "       0.17825083, 0.17899088, 0.17729123, 0.14493301, 0.14036674,\n",
        "       0.14594953, 0.14555512, 0.14836481, 0.14872669, 0.15042227,\n",
        "       0.15201213, 0.15363451, 0.14549412, 0.14741334]"
      ],
      "metadata": {
        "id": "QuhAwAHeOjLx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the number of time points in the sliced sequences\n",
        "Gives the number of time point in the data and the maxnimum length of the time points in a single sequence of the data.\n"
      ],
      "metadata": {
        "id": "FoLqZ4l1JNIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_time (data):\n",
        "  \"\"\"Returns Maximum sequence length and each sequence length.\n",
        "\n",
        "  Args:\n",
        "    - data: original data\n",
        "\n",
        "  Returns:\n",
        "    - time: extracted time information\n",
        "    - max_seq_len: maximum sequence length\n",
        "  \"\"\"\n",
        "  time = list()\n",
        "  max_seq_len = 0\n",
        "  for i in range(len(data)):\n",
        "    max_seq_len = max(max_seq_len, len(data[i][:,0]))\n",
        "    time.append(len(data[i][:,0]))\n",
        "\n",
        "  return time, max_seq_len"
      ],
      "metadata": {
        "id": "0coBXdwoBB1y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "ULMVFwafsPE6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_cell(module_name, hidden_dim):\n",
        "  \"\"\"Basic RNN Cell.\n",
        "\n",
        "  Args:\n",
        "    - module_name: gru, lstm, or lstmLN\n",
        "\n",
        "  Returns:\n",
        "    - rnn_cell: RNN Cell\n",
        "  \"\"\"\n",
        "  assert module_name in ['gru','lstm','lstmLN']\n",
        "\n",
        "  # GRU\n",
        "  if (module_name == 'gru'):\n",
        "    rnn_cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "  # LSTM\n",
        "  elif (module_name == 'lstm'):\n",
        "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "  # LSTM Layer Normalization\n",
        "  elif (module_name == 'lstmLN'):\n",
        "    rnn_cell = tf.contrib.rnn.LayerNormBasicLSTMCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "  return rnn_cell"
      ],
      "metadata": {
        "id": "dQ05khnSoX24"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function generates a batch of random vectors, where each vector has a specified sequence length (from T_mb) and a fixed dimensionality (z_dim). The total number of vectors generated is batch_size."
      ],
      "metadata": {
        "id": "BZHprIdIyO9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_generator (batch_size, z_dim, T_mb, max_seq_len):\n",
        "  \"\"\"Random vector generation.\n",
        "\n",
        "  Args:\n",
        "    - batch_size: size of the random vector\n",
        "    - z_dim: dimension of random vector\n",
        "    - T_mb: time information for the random vector\n",
        "    - max_seq_len: maximum sequence length\n",
        "\n",
        "  Returns:\n",
        "    - Z_mb: generated random vector\n",
        "  \"\"\"\n",
        "  for i in range(batch_size):\n",
        "    temp = np.zeros([max_seq_len, z_dim])\n",
        "    temp_Z = np.random.uniform(0., 1, [T_mb[i], z_dim])\n",
        "    temp[:T_mb[i],:] = temp_Z\n",
        "    list().append(temp_Z)\n",
        "  return list()"
      ],
      "metadata": {
        "id": "oDBqlWdbq2lj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_generator(data, time, batch_size):\n",
        "  \"\"\"Mini-batch generator.\n",
        "\n",
        "  Args:\n",
        "    - data: time-series data\n",
        "    - time: time information\n",
        "    - batch_size: the number of samples in each batch\n",
        "\n",
        "  Returns:\n",
        "    - X_mb: time-series data in each batch\n",
        "    - T_mb: time information in each batch\n",
        "  \"\"\"\n",
        "  no = len(data)\n",
        "  idx = np.random.permutation(no)\n",
        " train_idx = idx[:batch_size]\n",
        "\n",
        "  X_mb = list(data[i] for i in train_idx)\n",
        "  T_mb = list(time[i] for i in train_idx)\n",
        "\n",
        "  return X_mb, T_mb"
      ],
      "metadata": {
        "id": "t0YJgj7MyUcj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [2, 4, 3, 4, 5]\n",
        "time = [1,2,4,6,7]\n",
        "batch_size = 2\n",
        "no = len(data)\n",
        "idx = np.random.permutation(no)\n",
        "print(\"idx\", idx)\n",
        "train_idx = idx[:batch_size]\n",
        "print(\"train_idx\", train_idx)\n",
        "X_mb= list(data[i] for i in train_idx)\n",
        "T_mb = list(time[i] for i in train_idx)\n",
        "X_mb, T_mb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E05hR1I3zTsE",
        "outputId": "ba0f9553-8714-4253-8a2b-bfc6342e7838"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx [1 3 0 4 2]\n",
            "train_idx [1 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4, 4], [2, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ryGzczsWzjQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}