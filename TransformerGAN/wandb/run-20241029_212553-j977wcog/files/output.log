/home/ymax29os/GANs/ams_project-2/transformer_GAN/transformer_model.py:94: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
/home/ymax29os/.local/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/home/ymax29os/GANs/ams_project-2/transformer_GAN/transformer_model.py:133: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
/home/ymax29os/.local/lib/python3.9/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
Traceback (most recent call last):
  File "/home/ymax29os/GANs/ams_project-2/transformer_GAN/main.py", line 52, in <module>
    generator = train_transformer_model(
  File "/home/ymax29os/GANs/ams_project-2/transformer_GAN/transformer_model.py", line 137, in train_transformer_model
    gp = gradient_penalty(discriminator, real_batch, fake_data.detach(), device)
NameError: name 'gradient_penalty' is not defined
