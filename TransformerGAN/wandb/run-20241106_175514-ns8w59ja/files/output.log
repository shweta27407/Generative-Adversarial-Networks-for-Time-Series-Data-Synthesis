/home/ymax29os/GANs/ams_project-2/transformer_GAN/transformer_model.py:94: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
/home/ymax29os/.local/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/home/ymax29os/GANs/ams_project-2/transformer_GAN/transformer_model.py:133: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
/home/ymax29os/.local/lib/python3.9/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/home/ymax29os/GANs/ams_project-2/transformer_GAN/transformer_model.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
Epoch [1/10] 	 Discriminator Loss: 0.0742 	 Generator Loss: 0.1212
Epoch [2/10] 	 Discriminator Loss: 0.0482 	 Generator Loss: 0.3116
Epoch [3/10] 	 Discriminator Loss: 0.0802 	 Generator Loss: 0.3169
Epoch [4/10] 	 Discriminator Loss: 0.0589 	 Generator Loss: 0.3064
Epoch [5/10] 	 Discriminator Loss: 0.1226 	 Generator Loss: 0.1069
Epoch [6/10] 	 Discriminator Loss: 0.0202 	 Generator Loss: 0.3670
Epoch [7/10] 	 Discriminator Loss: 0.0900 	 Generator Loss: 0.0673
Epoch [8/10] 	 Discriminator Loss: 0.0857 	 Generator Loss: 0.0864
Epoch [9/10] 	 Discriminator Loss: 0.0693 	 Generator Loss: 0.1037
Epoch [10/10] 	 Discriminator Loss: 0.0972 	 Generator Loss: 0.1332
Saving synthetic data:
/home/ymax29os/.local/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
[1m[34mDiscriminative Score: 0.5000[0m
/home/ymax29os/GANs/ams_project-2/transformer_GAN/metrics/predictive_metric.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  ori_data = torch.tensor(ori_data, dtype=torch.float32).to(device)
/home/ymax29os/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)
/home/ymax29os/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)
[1m[34mPredictive Score: 0.6230[0m
