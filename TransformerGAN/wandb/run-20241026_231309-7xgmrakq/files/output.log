/home/ymax29os/ams_project-2/transformer_GAN/transformer_model.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
/home/ymax29os/.local/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
Size of real_batch: torch.Size([64, 50, 22])
/home/ymax29os/ams_project-2/transformer_GAN/transformer_model.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
/home/ymax29os/.local/lib/python3.9/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/home/ymax29os/ams_project-2/transformer_GAN/transformer_model.py:133: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Size of real_batch: torch.Size([64, 50, 22])
Epoch [1/1] 	 Discriminator Loss: 0.0822 	 Generator Loss: 0.0957
Saving synthetic data:
/home/ymax29os/.local/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Traceback (most recent call last):
  File "/home/ymax29os/ams_project-2/transformer_GAN/main.py", line 93, in <module>
    discriminative_score = discriminative_score_metric(transformer_discriminator, real_data, synthetic_data, device)
  File "/home/ymax29os/ams_project-2/transformer_GAN/metrics/discriminative_metric.py", line 55, in discriminative_score_metric
    optimizer.step()
  File "/home/ymax29os/.local/lib/python3.9/site-packages/torch/optim/optimizer.py", line 484, in wrapper
    out = func(*args, **kwargs)
  File "/home/ymax29os/.local/lib/python3.9/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ymax29os/.local/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    adam(
  File "/home/ymax29os/.local/lib/python3.9/site-packages/torch/optim/optimizer.py", line 161, in maybe_fallback
    return func(*args, **kwargs)
  File "/home/ymax29os/.local/lib/python3.9/site-packages/torch/optim/adam.py", line 766, in adam
    func(
  File "/home/ymax29os/.local/lib/python3.9/site-packages/torch/optim/adam.py", line 431, in _single_tensor_adam
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt
